{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning Agent Demo\n",
    "\n",
    "This notebook demonstrates training a Q-learning agent for sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from agent.q_learning import QLearningAgent\n",
    "from environments.sentiment_env import SentimentEnv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = SentimentEnv(\n",
    "    dataset_name='imdb',\n",
    "    split='train',\n",
    "    use_subset=True,\n",
    "    subset_size=500\n",
    ")\n",
    "\n",
    "# Create agent\n",
    "agent = QLearningAgent(\n",
    "    actions=env.get_all_sentiments(),\n",
    "    alpha=0.1,\n",
    "    gamma=0.9,\n",
    "    epsilon=0.3,\n",
    "    epsilon_decay=0.995\n",
    ")\n",
    "\n",
    "print(f\"Environment: {len(env.dataset)} samples\")\n",
    "print(f\"Actions: {agent.actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_episodes = 200\n",
    "\n",
    "# Metrics\n",
    "episode_rewards = []\n",
    "episode_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for episode in range(num_episodes):\n",
    "    # Reset environment\n",
    "    text, true_label = env.reset()\n",
    "    \n",
    "    # Agent predicts\n",
    "    prediction = agent.predict(text, explore=True)\n",
    "    \n",
    "    # Environment step\n",
    "    _, reward, done, info = env.step(prediction)\n",
    "    \n",
    "    # Agent learns\n",
    "    agent.learn(text, prediction, reward, done=True)\n",
    "    \n",
    "    # Decay epsilon\n",
    "    agent.decay_epsilon()\n",
    "    \n",
    "    # Track metrics\n",
    "    episode_rewards.append(reward)\n",
    "    episode_accuracies.append(int(info['correct']))\n",
    "    \n",
    "    if (episode + 1) % 50 == 0:\n",
    "        recent_acc = np.mean(episode_accuracies[-50:])\n",
    "        print(f\"Episode {episode + 1}: Accuracy = {recent_acc:.3f}, Epsilon = {agent.epsilon:.3f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Rewards\n",
    "window = 20\n",
    "ma_rewards = np.convolve(episode_rewards, np.ones(window)/window, mode='valid')\n",
    "axes[0].plot(episode_rewards, alpha=0.3, label='Episode Reward')\n",
    "axes[0].plot(range(window-1, len(episode_rewards)), ma_rewards, label=f'{window}-Episode MA', linewidth=2)\n",
    "axes[0].set_xlabel('Episode')\n",
    "axes[0].set_ylabel('Reward')\n",
    "axes[0].set_title('Episode Rewards')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ma_acc = np.convolve(episode_accuracies, np.ones(window)/window, mode='valid')\n",
    "axes[1].plot(episode_accuracies, alpha=0.3, label='Episode Accuracy')\n",
    "axes[1].plot(range(window-1, len(episode_accuracies)), ma_acc, label=f'{window}-Episode MA', linewidth=2)\n",
    "axes[1].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random Baseline')\n",
    "axes[1].set_xlabel('Episode')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Learning Curve')\n",
    "axes[1].set_ylim([-0.05, 1.05])\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test samples\n",
    "test_texts = [\n",
    "    \"This movie was absolutely amazing! I loved every minute of it.\",\n",
    "    \"Terrible waste of time. Would not recommend.\",\n",
    "    \"The film was okay, nothing special.\"\n",
    "]\n",
    "\n",
    "print(\"Testing trained agent:\\n\")\n",
    "for text in test_texts:\n",
    "    prediction = agent.predict(text, explore=False)\n",
    "    q_values = agent.get_state_action_values(text)\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Q-values: {q_values}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = agent.get_stats()\n",
    "print(\"Agent Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
